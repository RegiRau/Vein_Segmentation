{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RegiRau/Vein_Segmentation/blob/main/Train_Vein_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9NvzAjeEjSk"
      },
      "source": [
        "# Train Vein Segmentation Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://git_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@github.com/RegiRau/Vein_Segmentation.git\n",
        "\n",
        "# #Download git-lfs to Push Files larger than 100MB.\n",
        "# os.chdir('/content')\n",
        "# !wget -O git-lfs.tar.gz https://github.com/git-lfs/git-lfs/releases/download/v2.13.2/git-lfs-linux-amd64-v2.13.2.tar.gz\n",
        "# !tar xzf git-lfs.tar.gz\n",
        "# !bash ./install.sh\n",
        "# !git lfs install\n",
        "# %cd Retinal-Vessel-Segmentation-using-variants-of-UNET\n",
        "# #FILE_NAME is the file with size >100MB and you wants to PUSH to GITHUB\n",
        "# !git lfs track 04_Vein_Dataset\n",
        "# !git add 04_Vein_Dataset/\n",
        "# !git commit -m \"added 04_Vein_Dataset\"\n",
        "# !git push"
      ],
      "metadata": {
        "id": "0Vap6TfbUi1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aokGRhyjWufN",
        "outputId": "c93dd062-5ea0-41d5-d420-01e683217d2b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "Wed Apr  6 15:21:34 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    27W /  70W |    266MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoUQcJ7mWw9z",
        "outputId": "be7f814b-c99d-4c43-f620-55ae713c8162"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qq\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6elYAN8WQxn",
        "outputId": "162afaa0-f7f8-446e-86e9-97996100d582"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "The folder you are executing pip from can no longer be found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data\n",
        "Train/Validation/Test Split: 70/15/15"
      ],
      "metadata": {
        "id": "pruwCzG8SJGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPgKreNdnasW",
        "outputId": "df2bb40d-3bd6-4b8f-b0ff-798f5d5492f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_number = 'run_2'\n",
        "!mkdir '/content/gdrive/MyDrive/Vein_Segmentation_Models'\n",
        "!mkdir '/content/gdrive/MyDrive/Vein_Segmentation_Models/run_1'\n",
        "!mkdir '/content/gdrive/MyDrive/Vein_Segmentation_Models/run_1/Checkpoints_training1'\n",
        "!mkdir '/content/gdrive/MyDrive/train_test_split'\n",
        "!mkdir '/content/gdrive/MyDrive/train_test_split/run_1'\n",
        "!mkdir '/content/gdrive/MyDrive/train_test_split/run_1/training1'\n",
        "\n",
        "# !mkdir '/content/gdrive/MyDrive/Datasets'\n",
        "# !mkdir '/content/gdrive/MyDrive/Datasets/run_1'\n",
        "# !mkdir '/content/gdrive/MyDrive/Datasets/run_1/train'\n",
        "# !mkdir '/content/gdrive/MyDrive/Datasets/run_1/test'\n",
        "# !mkdir '/content/gdrive/MyDrive/Datasets/run_1/val'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOaDSkiP6iOs",
        "outputId": "804829e8-2db1-45c6-e2b9-6b482422dcc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/Vein_Segmentation_Models’: File exists\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/Vein_Segmentation_Models/run_1’: File exists\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/Vein_Segmentation_Models/run_1/Checkpoints_training1’: File exists\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgHlnJJkpamB",
        "outputId": "c56f5553-a49d-4461-ee7f-906acc89cf12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "Archive:  /content/gdrive/MyDrive/Vein_Dataset_Resized.zip\n",
            "replace /content/Vein_Dataset_Resized/images/001_image01_L.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/gdrive/MyDrive/Vein_Dataset_Resized.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "run_number = 'run_1'\n",
        "\n",
        "# Initialize wandb with your project name\n",
        "run = wandb.init(project=\"Vein_Segmentation\", name=\"run_1_training1\", entity=\"regirau\",\n",
        "                 config = {\"learning_rate\": 1e-3,\n",
        "                           \"epochs\": 150,\n",
        "                            \"batch_size\": 3}\n",
        "                )\n",
        "config = wandb.config  # We'll use this to configure our experiment\n",
        "\n",
        "wandb_callback = WandbCallback(monitor='val_loss',\n",
        "                               log_weights=True,\n",
        "                               log_evaluation=True)\n"
      ],
      "metadata": {
        "id": "2ephqjYnXKc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "568f7fff-4de3-4b27-8cb5-dc9f666f676a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Start with settings from wandb library singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0msettings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSettings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0msettings_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"settings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Settings\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__copy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36m__copy__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProperty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# todo: double-check source, shouldn't it be Source.ENV?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"root_dir\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Exception' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                 \u001b[0mformatted_exceptions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "scsakoqTdWYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset"
      ],
      "metadata": {
        "id": "pRdKUQYGvsUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "dataset_images = tf.data\n",
        "dataset_labels = tf.data\n",
        "SIZE_X = 1632\n",
        "SIZE_Y = 1216\n",
        "\n",
        "\n",
        "dataset_images = tf.keras.utils.image_dataset_from_directory(\"Vein_Dataset_Resized/images\", labels=None, label_mode=None, color_mode=\"grayscale\", batch_size=1, image_size=(SIZE_Y, SIZE_X), shuffle=False, )\n",
        "dataset_labels = tf.keras.utils.image_dataset_from_directory(\"Vein_Dataset_Resized/labels\", labels=None, label_mode=None, color_mode=\"grayscale\", batch_size=1, image_size=(SIZE_Y, SIZE_X), shuffle=False, )\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "dataset_labels = dataset_labels.map(lambda x: (normalization_layer(x)))\n",
        "\n",
        "Vein_Dataset = tf.data.Dataset.zip((dataset_images, dataset_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "2dqzDgfcTalv",
        "outputId": "51ed32ed-ff79-4072-bd41-343fd2ab92d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files belonging to 1 classes.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-54-e4ee67330878>\", line 8, in <module>\n",
            "    dataset_images = tf.keras.utils.image_dataset_from_directory(\"Vein_Dataset_Resized/images\", labels=None, label_mode=None, color_mode=\"grayscale\", batch_size=1, image_size=(SIZE_Y, SIZE_X), shuffle=False, )\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image_dataset.py\", line 209, in image_dataset_from_directory\n",
            "    raise ValueError(f'No images found in directory {directory}. '\n",
            "ValueError: No images found in directory Vein_Dataset_Resized/images. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.data.experimental.get_structure(\n",
        "#     Vein_Dataset\n",
        "# )"
      ],
      "metadata": {
        "id": "3axk_jo26WHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Wertebereich Label überprüfen\n",
        "# tensor = dataset_labels.take(1)\n",
        "# for image in tensor: print('max values', np.max(image[0, :, :, 0]))"
      ],
      "metadata": {
        "id": "e1F8jXb6c3mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def display(display_list):\n",
        "#   plt.figure(figsize=(15, 15))\n",
        "\n",
        "#   title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "#   for i in range(len(display_list)):\n",
        "#     plt.subplot(1, len(display_list), i+1)\n",
        "#     plt.title(title[i])\n",
        "#     plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "#     plt.axis('off')\n",
        "#   plt.show()\n",
        "\n",
        "# for images, masks in train_batches.take(2):\n",
        "#   sample_image, sample_mask = images[0], masks[0]\n",
        "#   display([sample_image, sample_mask])"
      ],
      "metadata": {
        "id": "iK9H13FLtgGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# def display(display_list):\n",
        "#   plt.figure(figsize=(15, 15))\n",
        "\n",
        "#   title = ['Input Image', 'Groundtruth']\n",
        "\n",
        "#   for i in range(len(display_list)):\n",
        "#     plt.subplot(1, len(display_list), i+1)\n",
        "#     plt.title(title[i])\n",
        "#     plt.imshow(display_list[i][:, :, 0], 'gray')\n",
        "#     #plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "#     plt.axis('off')\n",
        "#     print('max values', np.max(display_list[i][:, :, 0]))\n",
        "#   plt.show()\n",
        "\n",
        "# for images, masks in Vein_Dataset.take(2):\n",
        "#   #print(images.shape)\n",
        "#   sample_image, sample_mask = images[0], masks[0]\n",
        "#   display([sample_image, sample_mask])\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "VZK2Z-KFcoiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Val/Test Split"
      ],
      "metadata": {
        "id": "vFFTjJk8voia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Vein_Dataset.shuffle(buffer_size = 1000)\n",
        "\n",
        "Dataset_Size = 900\n",
        "\n",
        "train_size = int(0.7 * Dataset_Size)\n",
        "val_size = int(0.15 * Dataset_Size)\n",
        "test_size = int(0.15 * Dataset_Size)\n",
        "\n",
        "train_dataset = Vein_Dataset.take(train_size)\n",
        "test_dataset = Vein_Dataset.skip(train_size)\n",
        "val_dataset = test_dataset.skip(test_size)\n",
        "test_dataset = test_dataset.take(test_size)"
      ],
      "metadata": {
        "id": "Ph0sRohfvnPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train = train_dataset.map(lambda a, b: a)\n",
        "# y_train = train_dataset.map(lambda a, b: b)\n",
        "\n",
        "# x_val = val_dataset.map(lambda a, b: a)\n",
        "# y_val = val_dataset.map(lambda a, b: b)\n",
        "\n",
        "x_test = test_dataset.map(lambda a, b: a)\n",
        "y_test = test_dataset.map(lambda a, b: b)"
      ],
      "metadata": {
        "id": "pyfxr7SAOo8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset_Batch = train_dataset.batch(1)"
      ],
      "metadata": {
        "id": "1gyBRAXqGLPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#type(train_dataset_Batch)"
      ],
      "metadata": {
        "id": "Tjmcv8ygGTaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.data.experimental.save(\n",
        "#     train_dataset, '/content/gdrive/MyDrive/Datasets/run_1/train', compression=None, shard_func=None, checkpoint_args=None)\n",
        "# tf.data.experimental.save(\n",
        "#     test_dataset, '/content/gdrive/MyDrive/Datasets/run_1/test', compression=None, shard_func=None, checkpoint_args=None)\n",
        "# tf.data.experimental.save(\n",
        "#     val_dataset, '/content/gdrive/MyDrive/Datasets/run_1/val', compression=None, shard_func=None, checkpoint_args=None)"
      ],
      "metadata": {
        "id": "HGUi1_wVGnZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loaded = tf.data.experimental.load('/content/gdrive/MyDrive/Datasets/run_1/train')\n",
        "# test_loaded = tf.data.experimental.load('/content/gdrive/MyDrive/Datasets/run_1/test')\n",
        "# val_loaded = tf.data.experimental.load('/content/gdrive/MyDrive/Datasets/run_1/val')"
      ],
      "metadata": {
        "id": "eQn2GqW9RF6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(test_dataset)\n",
        "print(val_dataset)"
      ],
      "metadata": {
        "id": "9xPDLz8jNB4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "\n",
        "for images, masks in test_dataset.take(test_size):\n",
        "  sample_image, sample_mask = images[0, :, :, 0], masks[0, :, :, 0]\n",
        "  x_test.append(sample_image)\n",
        "  y_test.append(sample_mask)\n",
        "\n",
        "x_test =  np.array(x_test)\n",
        "y_test =  np.array(y_test)\n",
        "x_test = np.expand_dims(x_test,axis=-1)\n",
        "y_test = np.expand_dims(y_test,axis=-1)\n",
        "\n",
        "np.save('/content/gdrive/MyDrive/train_test_split/' + run_number + '/training1/x_test.npy', x_test)\n",
        "np.save('/content/gdrive/MyDrive/train_test_split/' + run_number + '/training1/y_test.npy', y_test)"
      ],
      "metadata": {
        "id": "tJ7OrO6RNXgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import datetime\n",
        "# import cv2\n",
        "# import skimage.io\n",
        "# import numpy as np\n",
        "# import os\n",
        "# np.random.seed(0)\n",
        "\n",
        "\n",
        "# #CLAHE\n",
        "# def clahe_equalized(imgs):\n",
        "#     clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "#     imgs_equalized = clahe.apply(imgs)\n",
        "#     return imgs_equalized\n",
        "\n",
        "# path1 = \"04_Vein_Dataset/images\"\n",
        "# path2 = \"04_Vein_Dataset/labels\"\n",
        "\n",
        "# image_dataset = []\n",
        "# mask_dataset = []\n",
        "\n",
        "# SIZE_X = 1632\n",
        "# SIZE_Y = 1216\n",
        "# images = sorted(os.listdir(path1))\n",
        "# for i, image_name in enumerate(images):\n",
        "#     image = cv2.imread(path1 + '/' + image_name, 0)\n",
        "#     image = clahe_equalized(image) #applying CLAHE\n",
        "#     image = cv2.resize(image, dsize=(SIZE_X, SIZE_Y), interpolation=cv2.INTER_CUBIC)\n",
        "#     image = np.array(image, dtype=\"float32\")\n",
        "#     image_dataset.append(image)\n",
        "\n",
        "# masks = sorted(os.listdir(path2))\n",
        "# for i, mask_name in enumerate(masks):\n",
        "#     mask = cv2.imread(path2 + '/' + mask_name, 0)\n",
        "#     mask = cv2.resize(mask, dsize=(SIZE_X, SIZE_Y), interpolation=cv2.INTER_CUBIC)\n",
        "#     mask[mask < 200] = 0\n",
        "#     mask[mask >= 200] = 1\n",
        "#     mask = np.array(mask, dtype=\"float32\")\n",
        "#     mask_dataset.append(mask)\n",
        "\n",
        "# image_dataset = np.array(image_dataset)\n",
        "# mask_dataset =  np.array(mask_dataset)\n",
        "# image_dataset = np.expand_dims(image_dataset,axis=-1)\n",
        "# mask_dataset =  np.expand_dims(mask_dataset,axis=-1)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# x_train, x_remain, y_train, y_remain = train_test_split(image_dataset, mask_dataset, test_size=0.3, random_state=0)\n",
        "# x_test, x_val, y_test, y_val= train_test_split(x_remain, y_remain, test_size=0.5, random_state=0)\n",
        "\n",
        "\n",
        "# np.save('/content/gdrive/MyDrive/train_test_split/' + run_number + '/x_test.npy', x_test)\n",
        "# np.save('/content/gdrive/MyDrive/train_test_split/' + run_number + '/y_test.npy', y_test)\n",
        "# np.save('/content/gdrive/MyDrive/train_test_split/' + run_number + '/x_val.npy', x_val)\n",
        "# np.save('/content/gdrive/MyDrive/train_test_split/' + run_number + '/y_val.npy', y_val)\n",
        "\n",
        "# # np.load('/content/gdrive/MyDrive/train_test_split/' + run_number + '/x_train.npy')\n",
        "# # np.load('/content/gdrive/MyDrive/train_test_split/' + run_number + '/y_train.npy')\n",
        "# # np.load('/content/gdrive/MyDrive/train_test_split/' + run_number + '/x_test.npy')\n",
        "# # np.load('/content/gdrive/MyDrive/train_test_split/' + run_number + '/y_test.npy')\n",
        "# # np.load('/content/gdrive/MyDrive/train_test_split/' + run_number + '/x_val.npy')\n",
        "# # np.load('/content/gdrive/MyDrive/train_test_split/' + run_number + '/y_val.npy')\n",
        "# # SIZE_X = 1632\n",
        "# # SIZE_Y = 1216\n",
        "\n",
        "# print('Shape of x_train: ', x_train.shape)\n",
        "# print('Shape of y_train: ', y_train.shape)\n",
        "# print('Shape of x_test: ', x_test.shape)\n",
        "# print('Shape of y_test: ', y_test.shape)\n",
        "# print('Shape of x_val: ', x_val.shape)\n",
        "# print('Shape of y_val: ', y_val.shape)\n",
        "\n",
        "# IMG_HEIGHT = SIZE_Y\n",
        "# IMG_WIDTH = SIZE_X"
      ],
      "metadata": {
        "id": "ccqAqLQqTMez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets = [x_test, y_test]\n",
        "# names = [\"x_test\", \"y_test\"]\n",
        "\n",
        "# raw_data = wandb.Artifact(\n",
        "#     \"Vein_Dataset_raw\", type=\"raw_data\", \n",
        "#     )\n",
        "\n",
        "\n",
        "# for name, data in zip(names, datasets):\n",
        "#     # 🐣 Store a new file in the artifact, and write something into its contents.\n",
        "#     with raw_data.new_file(name + \".npz\", mode=\"wb\") as file:\n",
        "#       np.savez(file, data)\n",
        "#     run.log_artifact(raw_data)\n"
      ],
      "metadata": {
        "id": "VTAXN5JeaUSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsOv81nnr648"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')\n",
        "print(\"TensorFlow **IS** using the GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2kp8hSmF9tv"
      },
      "source": [
        "# Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2GzbJ7GNofb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "#convolutional block\n",
        "def conv_block(x, kernelsize, filters, dropout, batchnorm=False): \n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(x)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(conv)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    return conv\n",
        "\n",
        "        \n",
        "    #skip connection    \n",
        "    shortcut = layers.Conv2D(filters, kernel_size=(1, 1), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "    shortcut = layers.Activation(\"relu\")(shortcut)\n",
        "    respath = layers.add([shortcut, conv2])       \n",
        "    return respath\n",
        "\n",
        "\n",
        "#gating signal for attention unit\n",
        "def gatingsignal(input, out_size, batchnorm=False):\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batchnorm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "#attention unit/block based on soft attention\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), kernel_initializer='he_normal', padding='same')(x) \n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), kernel_initializer='he_normal', padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3), strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]), kernel_initializer='he_normal', padding='same')(phi_g)\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), kernel_initializer='he_normal', padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg) \n",
        "    upsample_psi = layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': shape_x[3]})(upsample_psi)                          \n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), kernel_initializer='he_normal', padding='same')(y)\n",
        "    attenblock = layers.BatchNormalization()(result)\n",
        "    return attenblock\n",
        "\n",
        "#Attention U-NET\n",
        "def attentionunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "    \n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape) \n",
        "\n",
        "    # Downsampling layers    \n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "    \n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "    \n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "    \n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "    \n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers    \n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "    \n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "   \n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "    \n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "    \n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)  \n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()       \n",
        "    return model    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Evaluation Metrics"
      ],
      "metadata": {
        "id": "LU2ucl2idkxd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhfGbDFnDtdn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import jaccard_score,confusion_matrix\n",
        "\n",
        "\n",
        "def IoU_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def IoU_loss(y_true, y_pred):\n",
        "    return -IoU_coef(y_true, y_pred)\n",
        " \n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        " \n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "  \n",
        "def accuracy(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true.flatten(),y_pred.flatten(), labels=[0, 1])\n",
        "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    return acc\n",
        "  \n",
        "def IoU(y_true, y_pred, labels = [0, 1]):\n",
        "   IoU = []\n",
        "   for label in labels:\n",
        "      jaccard = jaccard_score(y_pred.flatten(),y_true.flatten(), pos_label=label, average='binary')\n",
        "      IoU.append(jaccard)     \n",
        "   return np.mean(IoU) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82YOEIh2WiW8"
      },
      "source": [
        "Give wandb.init your config\n",
        "\n",
        "You first initialize your wandb run, letting us know some training is about to happen.\n",
        "\n",
        "That's when you need to set your hyperparameters. They're passed in as a dictionary via the config argument, and then become available as the config attribute of wandb."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R0ox2RhUdPaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVPjS48AF6hG"
      },
      "outputs": [],
      "source": [
        "#importing models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.python.keras as keras\n",
        "\n",
        "# Initialize model like you usually do.\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "IMG_CHANNELS = 1\n",
        "SIZE_X = 1632\n",
        "SIZE_Y = 1216\n",
        "IMG_HEIGHT = SIZE_Y\n",
        "IMG_WIDTH = SIZE_X\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = attentionunet(input_shape, dropout=0.2)\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "\n",
        "#tensorflow.keras.utils.plot_model(model, \"Attention-Unet.png\", show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhebsvy8Wt3c"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(train_dataset, \n",
        "#                     epochs = 3,\n",
        "#                     batch_size = 3,\n",
        "#                     verbose=1,\n",
        "#                     validation_data=val_dataset,) "
      ],
      "metadata": {
        "id": "KS8adlpXSIYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9GvGVyxRWDl"
      },
      "outputs": [],
      "source": [
        "# create callbacks to continually save the model during training and at the end of training\n",
        "import os\n",
        "checkpoint_path = '/content/gdrive/MyDrive/Vein_Segmentation_Models/' + run_number + '/Checkpoints_training1/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# We train with our beloved model.fit\n",
        "# Notice WandbCallback is used as a regular callback\n",
        "# We again use config here\n",
        "# history = model.fit(x_train, y_train, \n",
        "#                     epochs = config.epochs,\n",
        "#                     batch_size = config.batch_size,\n",
        "#                     verbose=1,\n",
        "#                     validation_data=(x_val, y_val),)\n",
        "#                     callbacks=[cp_callback, WandbCallback()]) \n",
        "\n",
        "# Das ist das richtige:\n",
        "history = model.fit(train_dataset, \n",
        "                    epochs = config.epochs,\n",
        "                    batch_size = config.batch_size,\n",
        "                    verbose=1,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=[cp_callback, WandbCallback()]) \n",
        "\n",
        "\n",
        "os.listdir(checkpoint_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = run_number + '/model_run' + run_number[4] + '_training1'\n",
        "model.save('/content/gdrive/MyDrive/Vein_Segmentation_Models/' + model_name + '.hdf5')\n",
        "\n",
        "test_scores = model.evaluate(test_dataset, batch_size = config.batch_size, verbose=2)\n",
        "#test_scores = model.evaluate(x_test, y_test, batch_size = config.batch_size, verbose=2)"
      ],
      "metadata": {
        "id": "PmVIdCgc3fir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(model_name + '.h5')\n",
        "\n",
        "# # Save model as Model Artifact\n",
        "# artifact = wandb.Artifact(name=model_name + '.h5', type='model')\n",
        "# artifact.add_file(model_name + '.h5')\n",
        "# run.log_artifact(artifact)"
      ],
      "metadata": {
        "id": "ngHyTrL19PSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import jaccard_score,confusion_matrix\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "print('Shape of x_test: ', x_test.shape)\n",
        "print('Shape of y_test: ', y_test.shape)\n",
        "\n",
        "testimg = []\n",
        "ground_truth = []\n",
        "prediction = []\n",
        "global_IoU = []\n",
        "global_accuracy = []\n",
        "global_sensitivity = []\n",
        "global_specificity = []\n",
        "global_precision = []\n",
        "global_F1_Score = []\n",
        "\n",
        "for idx in range(x_test.shape[0]):\n",
        "    test_img = x_test[idx, :, :, 0]\n",
        "    testimg.append(test_img)\n",
        "    test_img_norm = (test_img.astype('float32')) / 255.\n",
        "    test_img_norm = np.expand_dims(np.array(test_img_norm), axis=-1)\n",
        "    test_img_input = np.expand_dims(test_img_norm, 0)\n",
        "    test_img_prediction = (model.predict(test_img_input)[0, :, :, 0] > 0.5).astype(\n",
        "        np.uint8)  # predict on single patch\n",
        "    prediction.append(test_img_prediction)\n",
        "\n",
        "    groundtruth = y_test[idx, :, :, 0]\n",
        "    groundtruth[groundtruth > 0.0] = 1.0\n",
        "    groundtruth = np.array(groundtruth, dtype=\"uint8\")\n",
        "    ground_truth.append(groundtruth)\n",
        "\n",
        "    y_true = groundtruth # 1 und 0\n",
        "    y_pred = test_img_prediction  # 1 and 0\n",
        "    labels = [0, 1]\n",
        "    IoU = []  #Intersection over Union -> Schwellenwert, um zu ermitteln, ob ein vorhergesagtes Ergebnis ein\n",
        "            #True Positive oder ein False Positive ist\n",
        "\n",
        "    for label in labels:\n",
        "      jaccard = jaccard_score(y_pred.flatten(),y_true.flatten(), pos_label=label, average='binary')\n",
        "      IoU.append(jaccard)\n",
        "    IoU = np.mean(IoU) #jacard/IoU of single image\n",
        "    global_IoU.append(IoU)\n",
        "\n",
        "    cm=[]\n",
        "    accuracy = []\n",
        "    cm = confusion_matrix(y_true.flatten(),y_pred.flatten(), labels=[1, 0])\n",
        "    #cm[0,0]: true positives, c[1,1]: true negatives, c[1,0]: false positives, c[0,1]: false negatives\n",
        "    accuracy = np.round((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1]), 4) #accuracy of single image\n",
        "    sensitivity = np.round(cm[0,0]/(cm[0,0]+cm[0,1]), 4)\n",
        "    specificity = np.round(cm[1,1]/(cm[1,1]+cm[1,0]), 4)\n",
        "    precision = np.round(cm[0,0]/(cm[0,0]+cm[1,0]), 4)\n",
        "    F1_Score = 2*precision*sensitivity/(precision+sensitivity)\n",
        "    global_accuracy.append(accuracy)\n",
        "    global_sensitivity.append(sensitivity)\n",
        "    global_specificity.append(specificity)\n",
        "    global_precision.append(precision)\n",
        "    global_F1_Score.append(F1_Score)\n",
        "\n",
        "\n",
        "avg_acc =  np.round(np.mean(global_accuracy), 4)\n",
        "avg_sens = np.round(np.mean(global_sensitivity), 4)\n",
        "avg_spec = np.round(np.mean(global_specificity), 4)\n",
        "mean_IoU = np.round(np.mean(global_IoU), 4)\n",
        "avg_F1_Score = np.round(np.mean(global_F1_Score), 4)\n",
        "\n",
        "print('Average accuracy is',avg_acc)\n",
        "print('Average sensitivity is', avg_sens)\n",
        "print('Average specificity is', avg_spec)\n",
        "print('mean IoU is',mean_IoU)\n",
        "print('Average F1-Score is', avg_F1_Score)"
      ],
      "metadata": {
        "id": "SCgUTRqUYSPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[avg_acc, avg_sens, avg_spec, mean_IoU, avg_F1_Score]]\n",
        "wandb.log({\"Evaluation_Table_run1_training1\": wandb.Table(data=data, columns=[\"Accuracy\", \"Sensitivity\", \"Specificity\", \"IoU\", \"F1-Score\"])})"
      ],
      "metadata": {
        "id": "tiLdYn80Xj_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create Artifact with segmentation results\n",
        "\n",
        "ds = wandb.Artifact(\"segmentation_results_test_data_run1_training1\", \"dataset\")\n",
        "test_table = wandb.Table(columns=[\"Image\", \"Groundtrugh\", \"Prediction\"], data=[])\n",
        "for i, g, p in zip(testimg, ground_truth, prediction):\n",
        "  test_table.add_data(wandb.Image(i), wandb.Image(g), wandb.Image(p))\n",
        "ds['test_data']=test_table\n",
        "ds.save()"
      ],
      "metadata": {
        "id": "9NZZLitQmlJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwDs8A7kdSjS"
      },
      "outputs": [],
      "source": [
        "#training-validation loss curve\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "fig1 = plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#training-validation accuracy curve\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "fig2 = plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'y', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracies')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#training-validation IoU curve\n",
        "iou_coef = history.history['IoU_coef']\n",
        "val_iou_coef = history.history['val_IoU_coef']\n",
        "fig3 = plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, iou_coef, 'r', label='Training IoU')\n",
        "plt.plot(epochs, val_iou_coef, 'y', label='Validation IoU')\n",
        "plt.title('Training and validation IoU coefficients')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "1RS-D2_NSMTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8u5zTMRdCSU"
      },
      "source": [
        "# GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DMGGeQ86rwG"
      },
      "outputs": [],
      "source": [
        "#%cd Retinal-Vessel-Segmentation-using-variants-of-UNET\n",
        "# !git status\n",
        "# !git add -u\n",
        "# !git add Veins_Trained_models/Veins_Attention_Unet_12images_10epochs_02.hdf5\n",
        "# !git add logs/\n",
        "# !git config --global user.email \"rerau9494@gmail.com\"\n",
        "# !git config --global user.name \"RegiRau\"\n",
        "# !git commit -m \"test model 31.03.2022\"\n",
        "# !git push"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Train_Vein_Segmentation.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}